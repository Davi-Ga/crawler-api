{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alexa\\Desktop\\crawler-api\\app\\ML\\modelo.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Desktop/crawler-api/app/ML/modelo.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Desktop/crawler-api/app/ML/modelo.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# For NLP\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexa/Desktop/crawler-api/app/ML/modelo.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Desktop/crawler-api/app/ML/modelo.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexa/Desktop/crawler-api/app/ML/modelo.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNetLemmatizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# For Data\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For NLP\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')# For Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  For Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar o Dataset\n",
    "df = pd.read_csv(\"dataset/Corona_NLP_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df['NOME DA FEATURE'].value_counts()[:10]\n",
    "fig = px.bar(x=feature.index,y=feature.values,text=feature.values,\n",
    "       color = feature.index, color_discrete_sequence=px.colors.sequential.deep,\n",
    "        title = 'Top 10 Locais',\n",
    "        template = 'simple_white')\n",
    "\n",
    "fig.update_traces(textposition='inside',\n",
    "                  textfont_size=11)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title = 'VALORES DO EIXO X',\n",
    "    yaxis_title = 'VALORES DO EIXO Y',\n",
    "    font=dict(size=17,family=\"Times New Roman\"),)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df, annot=True, cmap='coolwarm', linewidth=0.5)\n",
    "plt.title('Heatmap da Correlação de atributos ao Overall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Rotulacao\"])\n",
    "y = df[\"Rotulacao\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para a classificação de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_str(lst):\n",
    "    sentence = ''\n",
    "    for char in lst:\n",
    "        sentence += char+' '\n",
    "    sentence = sentence.lower()\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def get_word(text): \n",
    "    result = nltk.RegexpTokenizer(r'\\w+').tokenize(text.lower())\n",
    "    return result\n",
    "\n",
    "\n",
    "def stopword_list(stop):\n",
    "    lst = stopwords.words('english')\n",
    "    for stopword in stop:\n",
    "        lst.append(stopword)\n",
    "    return lst\n",
    "\n",
    "\n",
    "def remove_stopword(stopwords, lst):    \n",
    "    stoplist = stopword_list(stopwords)\n",
    "    txt = ''\n",
    "    for idx in range(len(lst)):\n",
    "        txt += lst[idx]\n",
    "        txt += '\\n'\n",
    "    cleanwordlist = [word for word in txt.split() if word not in stoplist] \n",
    "    return cleanwordlist\n",
    "\n",
    "\n",
    "def lemmatization(words):\n",
    "    lemm = WordNetLemmatizer()\n",
    "    tokens = [lemm.lemmatize(word) for word in words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def Word_Cloud(data, color_background, colormap, title):\n",
    "    plt.figure(figsize = (15,20))\n",
    "    wc = WordCloud(width=800, \n",
    "               height=400, \n",
    "               max_words=50,\n",
    "               colormap= colormap,\n",
    "               max_font_size=140,\n",
    "               random_state=8888, \n",
    "               background_color=color_background).generate_from_frequencies(data)\n",
    "    \n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratar texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreprocessor(featureRecord):\n",
    "    #Remove punctuations\n",
    "    removePunctuation = [char for char in featureRecord if char not in string.punctuation]\n",
    "    sentences =''.join(removePunctuation)\n",
    "\n",
    "    #convert sentences to words\n",
    "    words = sentences.split(\" \")\n",
    "\n",
    "    #normalize\n",
    "    wordNormalized=[word.lower() for word in words]\n",
    "\n",
    "    #remove stropwords\n",
    "    finalWords=[word for word in wordNormalized if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    finalWords = [stemmer.stem(word) for word in finalWords]\n",
    "\n",
    "    #joined = ' '.join(finalWords)\n",
    "\n",
    "    return finalWords\n",
    "\n",
    "# textPreprocessor(\"We need to STOCK UP in anticipation of a possible response or directive related to COVID-19 so we've created a SPECIFIC Amazon Wishlist.\\r\\r\\n.\\r\\r\\nFOOD Items include: black beans, shredded cheese, frozen meats, canned tuna,\\x85 https://t.co/NZAoPtKliy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Preprocessing\n",
    "df_frac = df.sample(frac=0.20, random_state=42)\n",
    "# df_frac = df.sample(frac=0.20, random_state=42) <-\n",
    "label = df_frac.iloc[:,0:3].values\n",
    "txt = df_frac.iloc[:,3].values\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Bag Of Words \n",
    "\n",
    "#Initialize Count Vectorizer with our custom preprocessing function\n",
    "\n",
    "wordVector = CountVectorizer(analyzer=textPreprocessor)\n",
    "\n",
    "#Build Vocab\n",
    "finalWordVocab = wordVector.fit(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalWordVocab.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(finalWordVocab.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Bag Of Words\n",
    "\n",
    "bagOfWords = finalWordVocab.transform(txt)\n",
    "\n",
    "bagOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Tfidf = TfidfVectorizer(stop_words='english', norm='l2' )\n",
    "X = Tfidf.fit_transform(df[\"Original_Text\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "colunas_categoricas = ['Label']\n",
    "\n",
    "one_hot_enc = make_column_transformer((OneHotEncoder(handle_unknown = 'ignore'),colunas_categoricas),remainder='passthrough')\n",
    "\n",
    "\n",
    "df = one_hot_enc.fit_transform(df)\n",
    "df = pd.DataFrame(df, columns=one_hot_enc.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> AVALIAÇÃO DO MODELO </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating a function to display model results\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def evaluation_parametrics(name,y_test, y_pred):\n",
    "    cm_test = confusion_matrix(y_test, y_pred )\n",
    "    t1 = ConfusionMatrixDisplay(cm_test, display_labels=[\"Positive\",\"Neutral\",\"Negative\"])    \n",
    "    print(\"Classification Report for Data Test\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    t1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "log = LogisticRegression(random_state=42)\n",
    "log.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = log.predict(X_test)\n",
    "\n",
    "micro_f1 = f1_score(y_test, y_pred,average='micro')\n",
    "macro_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "# print(\"Modelo Logist Regression\")\n",
    "# print(f\"Macro: {macro_f1} \")\n",
    "# print(f\"Micro: {micro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing model results\n",
    "evaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sgd = SGDClassifier(random_state=42,alpha=0.0001)\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "micro_f1 = f1_score(y_test, y_pred,average='micro')\n",
    "macro_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "\n",
    "print(\"Modelo SGD\")\n",
    "print(f\"Macro: {macro_f1} \")\n",
    "print(f\"Micro: {micro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing model results\n",
    "evaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (SUPORT VECTOR MACHINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_clf = LinearSVC(penalty=\"l2\", loss='squared_hinge',tol=0.0001, C=1, multi_class='ovr')\n",
    "\n",
    "lin_clf.fit(X=X_train, y=y_train, sample_weight=any)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, random_state=42, shuffle=False)\n",
    "rfc.fit(X=X_train, y=y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
